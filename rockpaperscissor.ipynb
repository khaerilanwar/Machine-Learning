{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFZgJyN_2jc9"
      },
      "outputs": [],
      "source": [
        "# import tensorflow\n",
        "import tensorflow as tf\n",
        "import zipfile, os, splitfolders\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmzeDQNu71Xv"
      },
      "outputs": [],
      "source": [
        "# Mengekstrak File Zip Dataset Machine Learning\n",
        "lokal_zip = '/tmp/rockpaperscissors.zip'\n",
        "zip_ext = zipfile.ZipFile(lokal_zip, 'r')\n",
        "zip_ext.extractall('/tmp')\n",
        "zip_ext.close()\n",
        "\n",
        "# Membagi isi direktori dataset menjadi 2 folder train dan val menggunakan split folders\n",
        "# Menggunakan rasio 60 : 40 dari dataset yang tersedia\n",
        "splitfolders.ratio('/tmp/rockpaperscissors/rps-cv-images', '/tmp/rockpaperscissors/dataset', seed=1, ratio=(.6, .4))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJw2c_tg6nMB"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan variabel direktori train dan validasi\n",
        "base_dir = '/tmp/rockpaperscissors/dataset'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'val')\n",
        "validation_dir\n",
        "os.listdir(train_dir)\n",
        "os.listdir(validation_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPnYti-aExo0"
      },
      "outputs": [],
      "source": [
        "# Mengecek Jumlah Data Sample pada direktori train\n",
        "list_train = os.listdir(train_dir)\n",
        "jumlah = 0\n",
        "\n",
        "for i in range(len(list_train)):\n",
        "  data = len(os.listdir(os.path.join(train_dir,list_train[i])))\n",
        "  jumlah += data\n",
        "  print(f\"Data {list_train[i]} = {data}\")\n",
        "else:\n",
        "  print(f\"Jumlah data train {jumlah}\\n\")\n",
        "\n",
        "# Mengecek Jumlah Data Sample pada direktori validasi\n",
        "list_val = os.listdir(validation_dir)\n",
        "jumlah = 0\n",
        "\n",
        "for i in range(len(list_val)):\n",
        "  data = len(os.listdir(os.path.join(validation_dir,list_val[i])))\n",
        "  jumlah += data\n",
        "  print(f\"Data {list_val[i]} = {data}\")\n",
        "else:\n",
        "  print(f\"Jumlah data validasi {jumlah}\")\n",
        "\n",
        "# Karena 60% dari 2188 sample data adalah 1312.8\n",
        "# Maka Python membulatkan sample datanya menjadi 1312 sample data\n",
        "\n",
        "# dan sisanya masuk ke data validasinya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfDZlbiaCRPz"
      },
      "outputs": [],
      "source": [
        "# Mendefinisakan variabel direktori train rps dan val rps secara terpisah\n",
        "train_rock_dir = os.path.join(train_dir, 'train')\n",
        "train_scissors_dir = os.path.join(train_dir, 'scissors')\n",
        "train_paper_dir = os.path.join(train_dir, 'paper')\n",
        "\n",
        "validation_crock_dir = os.path.join(validation_dir, 'rock')\n",
        "validation_scissors_dir = os.path.join(validation_dir, 'scissors')\n",
        "validation_paper_dir = os.path.join(validation_dir, 'paper')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDNa2I8RLUUJ"
      },
      "outputs": [],
      "source": [
        "# Augmentasi Gambar Menggunakan Image Data Generator dari library keras\n",
        "train_datagen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  shear_range=0.2,\n",
        "  fill_mode = \"nearest\")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "  rescale=1./255,\n",
        "  rotation_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  shear_range=0.2,\n",
        "  fill_mode = \"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iibPcgIyXeIS"
      },
      "outputs": [],
      "source": [
        "# Membuat flow datanya darimana dataset kita berasal\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  train_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=32,\n",
        "  class_mode='categorical')\n",
        "  \n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "  validation_dir,\n",
        "  target_size=(150, 150),\n",
        "  batch_size=32,\n",
        "  class_mode='categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PflgDqPgOVA"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ih9CPsRgmNQ"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOzjyrdQk1po"
      },
      "outputs": [],
      "source": [
        "history = model.fit(train_generator, \n",
        "          steps_per_epoch=25, \n",
        "          epochs=20, \n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=5,\n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahLwZoZ3xG6r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        " \n",
        "uploaded = files.upload()\n",
        " \n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        " \n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=32)\n",
        "\n",
        "  if classes[0,0]!=0:\n",
        "    print('PAPER')\n",
        "  elif classes[0,1]!=0:\n",
        "    print('ROCK')\n",
        "  else:\n",
        "    print('SCISSORS')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yI-hF0rEAt7V"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}